### BASH ###


# command/test [[]]

Arguments are separated from the command name and from each other by a whitespace.
This is wrong:

$ [-f file]


We want the command:	[	(which is a synonym for TEST) to be separated from the arguments: -f, file, and ].
If we do not separate [ and -f from each other with a whitespace, Bash will think we are trying to execute a command named [-f.
The arguments file and ] will also need to be separated by spaces.
Additionally, the command [ requires a closing argument of ].
The correct command separates all arguments with whitespaces:

$ [ -f file ]

If filename contains whitespace or other special characters, it should also be quoted:

$ [ -f "my file" ]

--------------------

## shebang
#!/usr/bin/env bash

## Verbose debugging
#!/usr/bin/bash -x


----- Special characters -----

$		-	EXPANSION - introduces various types of expansion:
			parameter expansion (e.g. $var or ${var})
			command substitution (e.g. $(command))
			arithmetic expansion (e.g. $((expression)))


\		-	ESCAPE - (backslash) prevents the next character from being interpreted as a special character.
			This works outside of quoting, inside double quotes, and generally ignored in single quotes.


[[ ]]	-	TEST - an evaluation of a conditional expression to determine whether it is "true" or "false".
			Tests are used in Bash to compare strings, check the existence of a file, etc.


{ }		-	INLINE GROUP - commands inside the curly braces are treated as if they were ONE COMMAND.
			It is convenient to use these when Bash syntax requires only one command and a function doesn't feel warranted.


( )		-	SUBSHELL GROUP - similar to the above but where commands within are executed in a SUBSHELL (a new process).
			Used much like a sandbox, if a command causes side effects (like changing variables), it will have no effect on the current shell.


(( ))	-	ARITHMETIC EXPRESSION - with an arithmetic expression, characters such as +, -, *, and / are mathematical operators used for calculations.
			They can be used for variable assignments like (( a = 1 + 4 )) as well as tests like if (( a < b )). More on this later.


$(( ))	-	ARITHMETIC EXPANSION - Comparable to the above, but the expression is replaced with the result of its arithmetic evaluation.
			Example: echo "The average is $(( (a+b)/2 ))".


--------------------

PARAMETER EXPANSION:
Any operation that causes a parameter to be expanded (replaced by content).
In its most basic appearance, the expansion of a parameter is achieved by prefixing that parameter with a $ sign.
In certain situations, additional curly braces around the parameter's name are required:

$ echo "'$USER', '$USERs', '${USER}s'"
'user1', '', 'user1s'

This example illustrates what basic parameter expansions (PE) look like.
The second PE results in an empty string.
That's because the parameter USERs is empty.
We did not intend to have the s be part of the parameter name.
Since there's no way Bash could know you want a literal 's' appended to the parameter's value, you need to use curly braces to mark the beginning and end of the parameter name.
That's what we do in the third PE in our example above.


Parameter Expansion also gives us tricks to modify the string that will be expanded.
These operations can be terribly convenient:

$ for file in *.JPG *.jpeg
do mv -- "$file" "${file%.*}.jpg"
done

The code above can be used to rename all JPEG files with a .JPG or a .jpeg extension to have a normal .jpg extension.
The expression ${file%.*} cuts off everything from the end starting with the last period (.).
Then, in the same quotes, a new extension is appended to the expansion result.

--------------------

## Special Parameters and Variables

Let's get our vocabulary straight before we get into the real deal.
There are Parameters and Variables.
Variables are actually just one kind of parameter: parameters that are denoted by a name.
Parameters that aren't variables are called Special Parameters.
I'm sure you'll understand things better with a few examples:


$ # Some parameters that aren't variables:
$ echo "My shell is $0, and has these options set: $-"
My shell is -bash, and has these options set: himB
$ # Some parameters that ARE variables:
$ echo "I am $LOGNAME, and I live at $HOME."
I am user1, and I live at /home/user1.

Please note: Unlike PHP/Perl/...
parameters do NOT start with a $-sign.
The $-sign you see in the examples merely causes the parameter that follows it to be expanded.
Expansion basically means that the shell replaces the parameter by its content.
As such, LOGNAME is the parameter (variable) that contains your username.
$LOGNAME is an expression that will be replaced with the content of that variable, which in my case is user1.

I think you've got the drift now.
Here's a summary of most of the Special Parameters:

----- Parameter Name	|	Usage	|	Description -----

0			"$0"		Contains the name, or the path, of the script. This is not always reliable.

1 2 etc.	"$1" etc.	Positional Parameters contain the arguments that were passed to the current script or function.

*			"$*"		Expands to all the words of all the positional parameters. Double quoted, it expands to a single string containing them all, separated by the first character of the IFS variable (discussed later).

@			"$@"		Expands to all the words of all the positional parameters. Double quoted, it expands to a list of them all as individual words.

#			$#			Expands to the number of positional parameters that are currently set.

?			$?			Expands to the exit code of the most recently completed foreground command.

$			$$			Expands to the PID (process ID number) of the current shell.

!			$!			Expands to the PID of the command most recently executed in the background.

_			"$_"	Expands to the last argument of the last command that was executed.


---------------------------------

# Examples of Variables that the shell provides:

BASH_VERSION: Contains a string describing the version of Bash.
HOSTNAME: Contains the hostname of your computer, I swear. Either short or long form, depending on how your computer is set up.
PPID: Contains the PID of the parent process of this shell.
PWD: Contains the current working directory.
RANDOM: Each time you expand this variable, a (pseudo)random number between 0 and 32767 is generated.
UID: The ID number of the current user. Not reliable for security/authentication purposes, alas.
COLUMNS: The number of characters that fit on one line in your terminal. (The width of your terminal in characters.)
LINES: The number of lines that fit in your terminal. (The height of your terminal in characters.)
HOME: The current user's home directory.
PATH: A colon-separated list of paths that will be searched to find a command, if it is not an alias, function, builtin command, or shell keyword, and no pathname is specified.
PS1: Contains a string that describes the format of your shell prompt.
TMPDIR: Contains the directory that is used to store temporary files (by the shell).

(There are many more -- see the manual for a comprehensive list.) Of course, you aren't restricted to only these variables. Feel free to define your own:

$ country=Canada
$ echo "I am $LOGNAME and I currently live in $country."
I am user1 and I currently live in Canada.

Notice what we did to assign the value Canada to the variable country. Remember that you are NOT allowed to have any spaces before or after that equals sign!

$ language = PHP
-bash: language: command not found
$ language=PHP
$ echo "I'm far too used to $language."
I'm far too used to PHP.

Remember that Bash is not Perl or PHP. You need to be very well aware of how expansion works to avoid big trouble. If you don't, you'll end up creating very dangerous situations in your scripts, especially when making this mistake with rm:

$ ls
no secret  secret
$ file='no secret'
$ rm $file
rm: cannot remove `no': No such file or directory

Imagine we have two files, no secret and secret
The first contains nothing useful, but the second contains the secret that will save the world from impending doom
Unthoughtful as you are, you forgot to quote your parameter expansion of file
Bash expands the parameter and the result is rm no secret
Bash splits the arguments up by their whitespace as it normally does, and rm is passed two arguments: 'no' and 'secret'
As a result, it fails to find the file no and it deletes the file secret
The secret is lost!

---------------------------------


### PATTERNS ###

BASH offers three different kinds of pattern matching

1. On the command line you will mostly use GLOBS
These are a fairly straight-forward form of patterns that can easily be used to match a range of files, or to check variables against simple rules

2. EXTENDED GLOBS, which allow more complicated expressions than regular globs

3. REGULAR EXPRESSIONS
These will be useful mainly in scripts to test user input or parse data
(You can't use a regular expression to select filenames; only globs and extended globs can do that)


Pattern matching serves two roles in the shell:
1. selecting filenames within a directory
2. Determining whether a string conforms to a desired format
 

--------------

## GLOB patterns

Globs are composed of normal characters and metacharacters.
Metacharacters are characters that have a special meaning.
These are the metacharacters that can be used in globs:

*: Matches any string, including the null string.
?: Matches any single character.
[...]: Matches any one of the enclosed characters.

Globs are implicitly anchored at both ends
What this means is that a glob must match a whole string (filename or data string)
A glob of a* will not match the string cat, because it only matches the at, not the whole string
A glob of ca*, however, would match cat.


Here's an example of how we can use glob patterns to expand to filenames:

$ ls
a  abc  b  c
$ echo *
a abc b c
$ echo a*
a abc

Bash sees the glob, for example a*
It expands this glob, by looking in the current directory and matching it against all files there.
Any filenames that match the glob are gathered up and sorted, and then the list of filenames is used in place of the glob.
As a result, the statement echo a* is replaced by the statement echo a abc, which is then executed.

When a glob is used to match filenames, the * and ? characters cannot match a slash (/) character.
So, for instance, the glob */bin might match foo/bin but it cannot match /usr/local/bin.
When globs match patterns, the / restriction is removed.

Bash performs filename expansions AFTER word splitting has already been done.
Therefore, filenames generated by a glob will not be split; they will always be handled correctly.
For example:

$ touch "a b.txt"
$ ls
a b.txt
$ rm *
$ ls

Here, * is expanded into the single filename "a b.txt"
This filename will be passed as a single argument to rm.
Using globs to enumerate files is always a better idea than using `ls` for that purpose.
Here's an example with some more complex syntax which we will cover later on, but it will illustrate the reason very well:

$ ls
a b.txt
$ for file in `ls`; do rm "$file"; done
rm: cannot remove `a': No such file or directory
rm: cannot remove `b.txt': No such file or directory
$ for file in *; do rm "$file"; done
$ ls

Here we use the for command to go through the output of the ls command.
The ls command prints the string a b.txt.
The for command splits that string into words over which it iterates.
As a result, for iterates over first a, and then b.txt.
Naturally, this is not what we want.
The glob, however, expands in the proper form.
It results in the string "a b.txt", which for takes as a single argument.

In addition to filename expansion, globs may also be used to check whether data matches a specific format.
For example, we might be given a filename, and need to take different actions depending on its extension:

$ filename="somefile.jpg"
$ if [[ $filename = *.jpg ]]; then
> echo "$filename is a jpeg"
> fi
somefile.jpg is a jpeg

The [[ keyword and the case keyword  both offer the opportunity to check a string against a glob -- either regular globs, or extended globs, if the latter have been enabled.

Good Practice:
You should always use globs instead of ls (or similar) to enumerate files.
Globs will always expand safely and minimize the risk for bugs.
You can sometimes end up with some very weird filenames.
Most scripts aren't tested against all the odd cases that they may end up being used with.
Don't let your script be one of those!


--------------

## EXTENDED GLOBS

These globs are more powerful in nature; technically, they are equivalent to regular expressions, although the syntax looks different than most people are used to.
This feature is turned off by default, but can be turned on with the SHOPT command, which is used to toggle shell options:

$ shopt -s extglob

?(list): Matches zero or one occurrence of the given patterns.
*(list): Matches zero or more occurrences of the given patterns.
+(list): Matches one or more occurrences of the given patterns.
@(list): Matches one of the given patterns.
!(list): Matches anything but the given patterns.

The list inside the parentheses is a list of globs or extended globs separated by the | character. Here's an example:

$ ls
names.txt  tokyo.jpg  california.bmp
$ echo !(*jpg|*bmp)
names.txt

Our extended glob expands to anything that does not match the *jpg or the *bmp pattern.
Only the text file passes for that, so it is expanded.

--------------

## REGULAR EXPRESSIONS

Regular expressions (regex) are similar to Glob Patterns, but they can only be used for PATTERN MATCHING, not for filename matching.
Since 3.0, Bash supports the =~ operator to the [[ keyword.
This operator matches the string that comes before it against the regex pattern that follows it.
When the string matches the pattern, [[ returns with an exit code of 0 ("true").
If the string does not match the pattern, an exit code of 1 ("false") is returned.
In case the pattern's syntax is invalid, [[ will abort the operation and return an exit code of 2.

Bash uses the Extended Regular Expression (ERE) dialect.
We will not cover regexes in depth in this guide, but if you are interested in this concept, please read up on RegularExpression, or Extended Regular Expressions.

Regular Expression patterns that use capturing groups (parentheses) will have their captured strings assigned to the BASH_REMATCH variable for later retrieval.

Let's illustrate how regex can be used in Bash:

$ langRegex='(..)_(..)'
$ if [[ $LANG =~ $langRegex ]]
> then
>     echo "Your country code (ISO 3166-1-alpha-2) is ${BASH_REMATCH[2]}."
>     echo "Your language code (ISO 639-1) is ${BASH_REMATCH[1]}."
> else
>     echo "Your locale was not recognised"
> fi

Be aware that regex parsing in Bash has changed between releases 3.1 and 3.2.
Before 3.2 it was safe to wrap your regex pattern in quotes but this has changed in 3.2.

Since then, REGEX SHOULD ALWAYS BE UNQUOTED.

You should protect any special characters by escaping it using a BACKSLASH.
The best way to always be compatible is to put your regex in a variable and expand that variable in [[ without quotes, as we showed above.

Good Practice:
Since the way regex is used in 3.2 is also valid in 3.1 we highly recommend you just never quote your regex.
Remember to keep special characters properly escaped!

For cross-compatibility (to avoid having to escape parentheses, pipes and so on) use a variable to store your regex, e.g.

re='^\*( >| *Applying |.*\.diff|.*\.patch)'; [[ $var =~ $re ]]

This is much easier to maintain since you only write ERE syntax and avoid the need for shell-escaping, as well as being compatible with all 3.x BASH versions.

--------------

BRACE EXPANSION

Brace Expansion technically does not fit in the category of patterns, but it is similar.
Globs only expand to actual filenames, but brace expansions will expand to ANY POSSIBLE PERMUTATION OF THEIR CONTENTS.

Here's how they work:

$ echo th{e,a}n
then than
$ echo {/home/*,/root}/.*profile
/home/axxo/.bash_profile /home/user1/.profile /root/.bash_profile /root/.profile
$ echo {1..9}
1 2 3 4 5 6 7 8 9
$ echo {0,1}{0..9}
00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19

The brace expansion is replaced by a list of words, just like a glob is.
However, these words aren't necessarily filenames, and they are not sorted (than would have come before then if they were).

Brace expansion happens before filename expansion.
In the second echo command above, we used a combination of brace expansion and globs.

The brace expansion goes first, and we get:

$ echo /home/*/.*profile /root/.*profile

After the brace expansion, the globs are expanded, and we get the filenames as the final result.

Brace expansions can only be used to generate lists of words.
They cannot be used for pattern matching.

There are a few interesting and not very intuitive differences between ranges in character classes like [a-z] and brace expansion.
E.g. brace expansion ALLOWS COUNTING BACKWARD, as can be seen with {5..1} or even {b..Y}, whereas [5-1] isn't expanded by the shell.
[b-Y] may or may not be expanded, depending on your locale.

Also, character ranges in brace expansions IGNORE LOCALE VARIABLES like LANG and LC_COLLATE and always use ASCII ordering.
Globbing on the other hand is affected by language settings.

The following fragment is an example for counting down and for displaying characters in the order of their ASCII codes:

$ echo {b..Y}
b a ` _ ^ ]  [ Z Y


---------------------------------



### TESTS AND CONDITIONALS ###

Sequential execution of commands is one thing, but to achieve any advanced logic in your scripts or your command line one-liners, you'll need tests and conditionals.
Tests determine whether something is true or false.
Conditionals are used to make decisions which determine the execution flow of a script.


## 1. Exit Status ##

Every command results in an exit code whenever it terminates.
This exit code is used by whatever application started it to evaluate whether everything went OK.
This exit code is like a return value from functions.
It's an integer between 0 and 255 (inclusive).
Convention dictates that we use 0 to denote success, and any other number to denote failure of some sort.
The specific number is entirely application-specific, and is used to hint as to what exactly went wrong.

For example, the ping command sends ICMP packets over the network to a certain host.
That host normally responds to this packet by sending the exact same one right back.
This way, we can check whether we can communicate with a remote host.
ping has a range of exit codes which can tell us what went wrong, if anything did:

From the Linux ping manual:

If ping does not receive any reply packets at all it will exit with code 1.
If a packet count and deadline are both specified, and fewer than count packets are received by the time the deadline has arrived, it will also exit with code 1.
On other error it exits with code 2.
Otherwise it exits with code 0.
This makes it possible to use the exit code to see if a host is alive or not.

The special parameter ? shows us the exit code of the last foreground process that terminated.

Let's play around a little with ping to see its exit codes:

$ ping God
ping: unknown host God
$ echo $?
2
$ ping -c 1 -W 1 1.1.1.1
PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.
--- 1.1.1.1 ping statistics ---
1 packets transmitted, 0 received, 100% packet loss, time 0ms
$ echo $?
1

Good Practice:
You should make sure that your scripts always return a non-zero exit code if something unexpected happened in their execution.
You can do this with the exit builtin:

 rm file || { echo 'Could not delete file!' >&2; exit 1; }

Exit Code / Exit Status: Whenever a command ends it notifies its parent (which in our case will always be the shell that started it) of its exit status.
This is represented by a number ranging from 0 to 255.
This code is a hint as to the success of the command's execution.



## 2. Control Operators (&& and ||)
Now that we know what exit codes are, and that an exit code of '0' means the command's execution was successful, we'll learn to use this information.
The easiest way of performing a certain action depending on the success of a previous command is through the use of control operators.
These operators are && and ||, which respectively represent a logical AND and a logical OR.
These operators are used between two commands, and they are used to control whether the second command should be executed depending on the success of the first.
This concept is called conditional execution.

Let's put that theory in practice:


$ mkdir d && cd d
This simple example has two commands, mkdir d and cd d.
You could use a semicolon there to separate the commands and execute them sequentially; but we want something more.
In the above example, BASH will execute mkdir d, then && will check the result of the mkdir application after it finishes.
If the mkdir application was successful (exit code 0), then Bash will execute the next command, cd d.
If mkdir d failed, and returned a non-0 exit code, Bash will skip the next command, and we will stay in the current directory.

Another example:

$ rm /etc/some_file.conf || echo "I couldn't remove the file"
rm: cannot remove `/etc/some_file.conf': No such file or directory
I couldn't remove the file

|| is much like &&, but it does the exact opposite.
It only executes the next command if the first failed.
As such, the message is only echoed if the rm command was unsuccessful.

In general, it's not a good idea to string together multiple different control operators in one command (we will explore this in the next section).
&& and || are quite useful in simple cases, but not in complex ones.
In the next few sections we'll show some other tools you can use for decision-making.

Good Practice:
It's best not to get overzealous when dealing with conditional operators.
They can make your script hard to understand, especially for a person that's assigned to maintain it and didn't write it themselves.

Control Operators: These operators are used to link commands together.
They check the exit code of the previous command to determine whether or not to execute the next command in the sequence.



## 3. Grouping Statements ##

Using conditional operators is easy and terse if we want to do simple error checking.
Things get a bit more dangerous, though, when we want to run multiple statements if a condition holds true, or if we need to evaluate multiple conditions.

Suppose you want to delete a file if it contains a certain "good" word but also doesn't contain another "bad" word.

Using grep (a command that checks its input for patterns), we translate these conditions to:

grep -q goodword "$file"            # exit status 0 (success) if "$file" contains 'goodword'
! grep -q "badword" "$file"         # exit status 0 (success) if "$file" does not contain 'badword'

We use -q (quiet) on grep because we don't want it to output the lines that match; we just want the exit code to be set.

The ! in front of a command causes Bash to negate the command's exit status.
If the command returns 0 (success), the ! turns it into a failure.
Likewise, if the command returns non-zero (failure), the ! turns it into a success.

Now, to put these conditions together and delete the file as a result of both holding true, we could use Conditional Operators:

$ grep -q goodword "$file" && ! grep -q badword "$file" && rm "$file"

This works great.
(In fact, we can string together as many && as we want, without any problems).
Now, imagine we want to show an error message in case the deletion of the file failed:

$ grep -q goodword "$file" && ! grep -q badword "$file" && rm "$file" || echo "Couldn't delete: $file" >&2

This looks OK, at first sight.

If rm's exit code is not 0 (success), then the || operator will trigger the next command and echo the error message (>&2: to standard error).

But there's a problem.
When we have a sequence of commands separated by Conditional Operators, Bash looks at every one of them, in order from left to right.
The exit status is carried through from whichever command was most recently executed, and skipping a command doesn't change it.

So, imagine the first grep fails (sets the exit status to 1).
Bash sees a && next, so it skips the second grep altogether.
Then it sees another &&, so it also skips the rm which follows that one.
Finally, it sees a || operator.

Aha! The exit status is "failure", and we have a ||, so Bash executes the echo command, and tells us that it couldn't delete a file -- even though it never actually tried to! That's not what we want.

This doesn't sound too bad when it's just a wrong error message you receive, but if you're not careful, this will eventually happen on more dangerous code.
You wouldn't want to accidentally delete files or overwrite files as a result of a failure in your logic!

The failure in our logic is in the fact that we want the rm and the echo statements to belong together.
The echo is related to the rm, not to the greps.
So what we need is to group them.

Grouping is done using curly braces:

$ grep -q goodword "$file" && ! grep -q badword "$file" && { rm "$file" || echo "Couldn't delete: $file" >&2; }
(Note: don't forget that you need a semicolon or newline before the closing curly brace!)

Now we've grouped the rm and echo command together.
That effectively means the group is considered one statement instead of several.
Going back to our situation of the first grep failing, instead of Bash trying the && rm "$file" statement, it will now try the && { ... } statement.
Since it is preceded by a && and the last command it ran failed (the failed grep), it will skip this group and move on.

Command grouping can be used for more things than just Conditional Operators.

We may also want to group them so that we can redirect input to a group of statements instead of just one:

{
    read firstLine
    read secondLine
    while read otherLine; do
        something
    done
} < file

Here we're redirecting file to a group of commands that read input.
The file will be opened when the command group starts, stay open for the duration of it, and be closed when the command group finishes.
This way, we can keep sequentially reading lines from it with multiple commands.

Another common use of grouping is in simple error handling:

# Check if we can go into appdir.  If not, output an error and exit the script.
cd "$appdir" || { echo "Please create the appdir and try again" >&2; exit 1; }



## 4. Conditional Blocks (if, test and [[) ##

if is a shell keyword that executes a command (or a set of commands), and checks that command's exit code to see whether it was successful.
Depending on that exit code, if executes a specific, different, block of commands.

$ if true
> then echo "It was true."
> else echo "It was false."
> fi
It was true.

Here you see the basic outline of an if-statement.
We start by calling if with the command true.
true is a builtin command that always ends successfully.
if runs that command, and once the command is done, if checks the exit code.
Since true always exits successfully, if continues to the then-block, and executes that code.
Should the true command have failed somehow, and returned an unsuccessful exit code, the if statement would have skipped the then code, and executed the else code block instead.

Different people have different preferred styles for writing if statements.

Here are some of the common styles:

if COMMANDS
then OTHER COMMANDS
fi

if COMMANDS
then
    OTHER COMMANDS
fi

if COMMANDS; then
    OTHER COMMANDS
fi
There are some commands designed specifically to test things and return an exit status based on what they find.
The first such command is test (also known as [).
A more advanced version is called [[.
[ or test is a normal command that reads its arguments and does some checks with them.
[[ is much like [, but it's special (a shell keyword), and it offers far more versatility.
Let's get practical:


$ if [ a = b ]
> then echo "a is the same as b."
> else echo "a is not the same as b."
> fi
a is not the same as b.

if executes the command [ (remember, you don't need an if to run the [ command!) with the arguments a, =, b and ].
[ uses these arguments to determine what must be checked.
In this case, it checks whether the string a (the first argument) is equal (the second argument) to the string b (the third argument), and if this is the case, it will exit successfully.
However, since the string "a" is not equal to the string "b", [ will not exit successfully (its exit code will be 1).
if sees that [ terminated unsuccessfully and executes the code in the else block.

The last argument, "]", means nothing to [, but it is required.
See what happens when you omit it.

Here's an example of a common pitfall when [ is used:

$ myname='Greg Wooledge' yourname='Someone Else'
$ [ $myname = $yourname ]
-bash: [: too many arguments
Can you guess what caused the problem?

[ was executed with the arguments Greg, Wooledge, =, Someone, Else and ].

That is 6 arguments, not 4! [ doesn't understand what test it's supposed to execute, because it expects either the first or second argument to be an operator.
In our case, the operator is the third argument.
Yet another reason why quotes are so terribly important.

Whenever we type whitespace in Bash that belongs together with the words before or after it, we need to quote it, and the same thing goes for parameter expansions:

$ [ "$myname" = "$yourname" ]

This time, [ sees an operator (=) in the second argument and it can continue with its work.

To help us out a little, the Korn shell introduced (and Bash adopted) a new style of conditional test.

Original as the Korn shell authors are, they called it [[.
[[ is loaded with several very interesting features that [ lacks.

One of the features of [[ is pattern matching:

$ [[ $filename = *.png ]] && echo "$filename looks like a PNG file"

Another feature of [[ helps us in dealing with parameter expansions:

$ [[ $me = $you ]]           # Fine.
$ [[ I am $me = I am $you ]] # Not fine!
-bash: conditional binary operator expected
-bash: syntax error near `am'

This time, $me and $you did not need quotes.
Since [[ isn't a normal command (like [ is), but a shell keyword, it has special magical powers.
It parses its arguments before they are expanded by Bash and does the expansion itself, taking the result as a single argument, even if that result contains whitespace.
(In other words, [[ does not allow word-splitting of its arguments.) However, be aware that simple strings still have to be quoted properly.
[[ treats a space outside of quotes as an argument separator, just like Bash normally would.

Let's fix our last example:

$ [[ "I am $me" = "I am $you" ]]

Also; there is a subtle difference between quoting and not quoting the right-hand side of the comparison in [[.
The = operator does pattern matching by default, whenever the right-hand side is not quoted:

$ foo=[a-z]* name=user1
$ [[ $name = $foo   ]] && echo "Name $name matches pattern $foo"
Name user1 matches pattern [a-z]*
$ [[ $name = "$foo" ]] || echo "Name $name is not equal to the string $foo"
Name user1 is not equal to the string [a-z]*

The first test checks whether $name matches the pattern in $foo.
The second test checks whether $name is equal to the string in $foo.
The quotes really do make that much difference -- a subtlety worth noting.

Remember: Quoting is usually going to give you the behavior that you want, so make it a habit; omit only when the specific situation requires unquoted behavior.
Unfortunately, bugs caused by incorrect quoting are often hard to find, because code is often valid with or without quotes, but may have different meanings.
In such cases, bash cannot tell that you did something wrong; it just does what you tell it, even if that's not what you intended.

You could also combine several if statements into one using elif instead of else, where each test indicates another possibility:

$ name=user1
$ if [[ $name = "George" ]]
> then echo "Bonjour, $name"
> elif [[ $name = "Hans" ]]
> then echo "Goeie dag, $name"
> elif [[ $name = "Jack" ]]
> then echo "Good day, $name"
> else
> echo "You're not George, Hans or Jack.
 Who the hell are you, $name?"
> fi

Note that "<" and ">" have special significance in bash.

Pop quiz: Predict what happens when you do [ apple < banana ].
Test your hypothesis (don't cheat by trying without first forming a hypothesis!).
Cue Jeopardy music...
Answer: bash looks for a file named "banana" in the current directory so that its contents can be sent to [ apple (via standard input).
Assuming you don't have a file named "banana" in your current directory, this will result in an error.

Pop quiz: Assuming the original intention of that command is determine whether "apple" comes before "banana", how would you change the command to get the desired effect? Cue Jeopardy music...
Answer: escape the "<" with a backslash like that: [ apple \< banana ] or use [[ instead of [.

Note that the comparison operators =, !=, >, and < treat their arguments as strings.
In order for the operands to be treated as numbers, you need to use one of a different set of operators: -eq, -ne (not equal), -lt (less than), -gt, -le (less than or equal to), or -ge.
Pop quiz: Come up with an example that shows the difference between < and -lt.

Since "314" comes before "9" lexicographically (i.e. the order that the dictionary would put them in), [ considers the former to be < than the later; whereas, [ considers "314" NOT to be -lt "9", because three hundred fourteen is NOT less than nine.

Now that you've got a decent understanding of quoting issues that may arise, let's have a look at some of the other features that [ and [[ were blessed with:

Tests supported by [ (also known as test) and [[:

-e FILE: True if file exists.
-f FILE: True if file is a regular file.
-d FILE: True if file is a directory.
-h FILE: True if file is a symbolic link.
-p PIPE: True if pipe exists.
-r FILE: True if file is readable by you.
-s FILE: True if file exists and is not empty.
-t FD : True if FD is opened on a terminal.
-w FILE: True if the file is writable by you.
-x FILE: True if the file is executable by you.
-O FILE: True if the file is effectively owned by you.
-G FILE: True if the file is effectively owned by your group.
FILE -nt FILE: True if the first file is newer than the second.
FILE -ot FILE: True if the first file is older than the second.
-z STRING: True if the string is empty (it's length is zero).
-n STRING: True if the string is not empty (it's length is not zero).

String operators:
STRING = STRING: True if the first string is identical to the second.
STRING != STRING: True if the first string is not identical to the second.
STRING < STRING: True if the first string sorts before the second.
STRING > STRING: True if the first string sorts after the second.
! EXPR: Inverts the result of the expression (logical NOT).

Numeric operators:
INT -eq INT: True if both integers are identical.
INT -ne INT: True if the integers are not identical.
INT -lt INT: True if the first integer is less than the second.
INT -gt INT: True if the first integer is greater than the second.
INT -le INT: True if the first integer is less than or equal to the second.
INT -ge INT: True if the first integer is greater than or equal to the second.

Additional tests supported only by [[:
STRING = (or ==) PATTERN: Not string comparison like with [ (or test), but pattern matching is performed. True if the string matches the glob pattern.
STRING != PATTERN: Not string comparison like with [ (or test), but pattern matching is performed. True if the string does not match the glob pattern.
STRING =~ REGEX: True if the string matches the regex pattern.
( EXPR ): Parentheses can be used to change the evaluation precedence.
EXPR && EXPR: Much like the '-a' operator of test, but does not evaluate the second expression if the first already turns out to be false.
EXPR || EXPR: Much like the '-o' operator of test, but does not evaluate the second expression if the first already turns out to be true.

Tests exclusive to [ (and test):
EXPR -a EXPR: True if both expressions are true (logical AND).
EXPR -o EXPR: True if either expression is true (logical OR).

# Examples:

$ test -e /etc/X11/xorg.conf && echo 'Your Xorg is configured!'
Your Xorg is configured!
$ test -n "$HOME" && echo 'Your homedir is set!'
Your homedir is set!
$ [[ boar != bear ]] && echo "Boars aren't bears."
Boars aren't bears!
$ [[ boar != b?ar ]] && echo "Boars don't look like bears."
$ [[ $DISPLAY ]] && echo "Your DISPLAY variable is not empty, you probably have Xorg running."
Your DISPLAY variable is not empty, you probably have Xorg running.
$ [[ ! $DISPLAY ]] && echo "Your DISPLAY variable is not not empty, you probably don't have Xorg running."

Good Practice:
Whenever you're making a Bash script, you should always use [[ rather than [.
Whenever you're making a Shell script, which may end up being used in an environment where Bash is not available, you should use [, because it is far more portable.
(While being built in to Bash and some other shells, [ should be available as an external application as well; meaning it will work as argument to, for example, find's -exec and xargs.)
Don't ever use the -a or -o tests of the [ command.
Use multiple [ commands instead (or use [[ if you can).
POSIX doesn't define the behavior of [ with complex sets of tests, so you never know what you'll get.

if [ "$food" = apple ] && [ "$drink" = tea ]; then
  echo "The meal is acceptable."
fi

if (keyword): Execute a list of commands and then, depending on their exit code, execute the code in the following then (or optionally else) block.



## 5. Conditional Loops (while, until and for) ##

Now you've learned how to make some basic decisions in your scripts.
However, that's not enough for every kind of task we might want to script.
Sometimes we need to repeat things.
For that, we need to use a loop.
There are two basic kinds of loops (plus a couple of variants), and using the correct kind of loop will help you keep your scripts readable and maintainable.

The two basic kinds of loops are called while and for.
The while loop has a variant called until which simply reverses its check; and the for loop can appear in two different forms.

Summary:

while command: Repeat so long as command is executed successfully (exit code is 0).
until command: Repeat so long as command is executed unsuccessfully (exit code is not 0).
for variable in words: Repeat the loop for each word, setting variable to each word in turn.
for (( expression; expression; expression )): Starts by evaluating the first arithmetic expression; repeats the loop so long as the second arithmetic expression is successful; and at the end of each loop evaluates the third arithmetic expression.

Each loop form is followed by the key word do, then one or more commands in the body, then the key word done.
The do and done are similar to the then and fi (and possible elif and/or else) from the if statement we saw earlier.
Their job is to tell us where the body of the loop begins and ends.

In practice, the loops are used for different kinds of tasks.
The for loop (first form) is appropriate when we have a list of things, and we want to run through that list sequentially.
The while loop is appropriate when we don't know exactly how many times we need to repeat something; we simply want it to keep going until we find what we're looking for.

Here are some examples to illustrate the differences and also the similarities between the loops.
(Remember: on most operating systems, you press Ctrl-C to kill a program that's running on your terminal.)


$ while true
> do echo "Infinite loop"
> done

$ while ! ping -c 1 -W 1 1.1.1.1; do
> echo "still waiting for 1.1.1.1"
> sleep 1
> done

$ (( i=10 )); while (( i > 0 ))
> do echo "$i empty cans of beer."
> (( i-- ))
> done
$ for (( i=10; i > 0; i-- ))
> do echo "$i empty cans of beer."
> done
$ for i in {10..1}
> do echo "$i empty cans of beer."
> done

The last three loops achieve exactly the same result, using different syntax.
You'll encounter this many times in your shell scripting experience.
There will nearly always be multiple approaches to solving a problem.
The test of your skill soon won't be about solving a problem as much as about how best to solve it.
You must learn to pick the best angle of approach for the job.
Usually, the main factors to take into account will be the simplicity and flexibility of the resulting code.
My personal favorite is the last of the examples.
In that example I used Brace Expansion to generate the words; but there are other ways, too.

Let's take a closer look at that last example, because although it looks the easier of the two fors, it can often be the trickier, if you don't know exactly how it works.

As I mentioned before: for runs through a list of words and puts each one in the loop index variable, one at a time, and then loops through the body with it.
The tricky part is how Bash decides what the words are.
Let me explain myself by expanding the braces from that previous example:


$ for i in 10 9 8 7 6 5 4 3 2 1
> do echo "$i empty cans of beer."
> done
Bash takes the characters between in and the end of the line, and splits them up into words.
This splitting is done on spaces and tabs, just like argument splitting.
However, if there are any unquoted substitutions in there, they will be word-split as well (using IFS).
All these split-up words become the iteration elements.

As a result, be VERY careful not to make the following mistake:


$ ls
The best song in the world.mp3
$ for file in $(ls *.mp3)
> do rm "$file"
> done
rm: cannot remove `The': No such file or directory
rm: cannot remove `best': No such file or directory
rm: cannot remove `song': No such file or directory
rm: cannot remove `in': No such file or directory
rm: cannot remove `the': No such file or directory
rm: cannot remove `world.mp3': No such file or directory
You should already know to quote the $file in the rm statement; but what's going wrong here? Bash expands the command substitution ($(ls *.mp3)), replaces it by its output, and then performs word splitting on it (because it was unquoted).
Essentially, Bash executes for file in The best song in the world.mp3.
Boom, you are dead.

You want to quote it, you say? Let's add another song:

$ ls
The best song in the world.mp3  The worst song in the world.mp3
$ for file in "$(ls *.mp3)"
> do rm "$file"
> done
rm: cannot remove `The best song in the world.mp3  The worst song in the world.mp3': No such file or directory
Quotes will indeed protect the whitespace in your filenames; but they will do more than that.
The quotes will protect all the whitespace from the output of ls.
There is no way Bash can know which parts of the output of ls represent filenames; it's not psychic.
The output of ls is a simple string, and Bash treats it as such.
The for puts the whole quoted output in i and runs the rm command with it.
Damn, dead again.

So what do we do? As suggested earlier, globs are your best friend:


$ for file in *.mp3
> do rm "$file"
> done
This time, Bash does know that it's dealing with filenames, and it does know what the filenames are, and as such it can split them up nicely.
The result of expanding the glob is this: for file in "The best song in the world.mp3" "The worst song in the world.mp3".
Problem solved!

Now let's look at the while loop.
The while loop is very interesting for its capacity to execute commands until something interesting happens.
Here are a few examples of how while loops are very often used:


$ # The sweet machine; hand out sweets for a cute price.
$ while read -p $'The sweet machine.\nInsert 20c and enter your name: ' name
> do echo "The machine spits out three lollipops at $name."
> done

$ # Check your email every five minutes.
$ while sleep 300
> do kmail --check
> done

$ # Wait for a host to come back online.
$ while ! ping -c 1 -W 1 "$host"
> do echo "$host is still unavailable."
> done; echo -e "$host is available again.\a"
The until loop is barely ever used, if only because it is pretty much exactly the same as while !.
We could rewrite our last example using an until loop:


$ # Wait for a host to come back online.
$ until ping -c 1 -W 1 "$host"
> do echo "$host is still unavailable."
> done; echo -e "$host is available again.\a"
In practice, most people simply use while ! instead.

Lastly, you can use the continue builtin to skip ahead to the next iteration of a loop without executing the rest of the body, and the break builtin to jump out of the loop and continue with the script after it.
This works in both for and while loops.

Loop: A loop is a structure that is designed to repeat the code within until a certain condition has been fulfilled.
At that point, the loop stops and the code beyond it is executed.

for (keyword): A for-loop is a type of loop that sets a variable to each of a list of values in turn, and repeats until the list is exhausted.

while (keyword): A while-loop is a type of loop that continues to run its code so long as a certain command (run before each iteration) executes successfully.

until (keyword): An until-loop is a type of loop that continues to run its code so long as a certain command (run before each iteration) executes unsuccessfully.




## 6. Choices (case and select) ##

Sometimes you want to build application logic depending on the content of a variable.

This could be implemented by taking a different branch of an if statement depending on the results of testing against a glob:

shopt -s extglob

if [[ $LANG = en* ]]; then
    echo 'Hello!'
elif [[ $LANG = fr* ]]; then
    echo 'Salut!'
elif [[ $LANG = de* ]]; then
    echo 'Guten Tag!'
elif [[ $LANG = nl* ]]; then
    echo 'Hallo!'
elif [[ $LANG = it* ]]; then
    echo 'Ciao!'
elif [[ $LANG = es* ]]; then
    echo 'Hola!'
elif [[ $LANG = @(C|POSIX) ]]; then
    echo 'hello world'
else
    echo 'I do not speak your language.'
fi

But all these comparisons are a bit redundant.
Bash provides a keyword called case exactly for this kind of situation.

A case statement basically enumerates several possible Glob Patterns and checks the content of your parameter against these:

case $LANG in
    en*) echo 'Hello!' ;;
    fr*) echo 'Salut!' ;;
    de*) echo 'Guten Tag!' ;;
    nl*) echo 'Hallo!' ;;
    it*) echo 'Ciao!' ;;
    es*) echo 'Hola!' ;;
    C|POSIX) echo 'hello world' ;;
    *)   echo 'I do not speak your language.' ;;
esac

Each choice in a case statement consists of a pattern (or a list of patterns with | between them), a right parenthesis, a block of code that is to be executed if the string matches one of those patterns, and two semi-colons to denote the end of the block of code (since you might need to write it on several lines).
A left parenthesis can be added to the left of the pattern.
Using ;& instead of ;; will grant you the ability to fall-through the case matching in bash, zsh and ksh.
case stops matching patterns as soon as one is successful.
Therefore, we can use the * pattern in the end to match any case that has not been caught by the other choices.

When a matching pattern is found and the ;& operator is used after the block of code, the block of code for the next choice will be executed too no matter if the pattern for that choice matches or not.
When the ;;& operator is used, instead of the block of code for the next choice, will be executed the block of code for the next matching pattern.

Another construct of choice is the select construct.
This statement smells like a loop and is a convenience statement for generating a menu of choices that the user can choose from.

The user is presented by choices and asked to enter a number reflecting his choice.
The code in the select block is then executed with a variable set to the choice the user made.
If the user's choice was invalid, the variable is made empty:


$ echo "Which of these does not belong in the group?"; \
> select choice in Apples Pears Crisps Lemons Kiwis; do
> if [[ $choice = Crisps ]]
> then echo "Correct!  Crisps are not fruit."; break; fi
> echo "Errr...
no.
 Try again."
> done

The menu reappears so long as the break statement is not executed.
In the example the break statement is only executed when the user makes the correct choice.

We can also use the PS3 variable to define the prompt the user replies on.
Instead of showing the question before executing the select statement, we could choose to set the question as our prompt:


$ PS3="Which of these does not belong in the group (#)? "; \
> select choice in Apples Pears Crisps Lemons Kiwis; do
> if [[ $choice = Crisps ]]
> then echo "Correct!  Crisps are not fruit."; break; fi
> echo "Errr...
no.
 Try again."
> done

All of these conditional constructs (if, for, while, and case) can be nested.
This means you could have a for loop with a while loop inside it, or any other combination, as deeply as you need to solve your problem.


# A simple menu:
while true; do
    echo "Welcome to the Menu"
    echo "  1.
Say hello"
    echo "  2.
Say good-bye"

    read -p "-> " response
    case $response in
        1) echo 'Hello there!' ;;
        2) echo 'See you later!'; break ;;
        *) echo 'What was that?' ;;
    esac
done

# Alternative: use a variable to terminate the loop instead of an
# explicit break command.

quit=
while test -z "$quit"; do
    echo "...."
    read -p "-> " response
    case $response in
        ...
        2) echo 'See you later!'; quit=y ;;
        ...
    esac
done

Good Practice:
A select statement makes a simple menu simple, but it doesn't offer much flexibility.
If you want something more elaborate, you might prefer to write your own menu using a while loop, some echo or printf commands, and a read command.

case (keyword): The case statement evaluates a parameter's value against several given patterns (choices).

select (keyword): The select statement offers the user the choice of several options and executes a block of code with the user's choice in a parameter.
The menu repeats until a break command is executed.


-------------------------------------------------


